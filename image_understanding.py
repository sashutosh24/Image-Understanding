# -*- coding: utf-8 -*-
"""Image Understanding

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gSsI901biJQ1Rjbe-5YLkXxvSbT7sl62
"""

pip install opencv-python deepface matplotlib

import cv2
from deepface import DeepFace
import matplotlib.pyplot as plt

# Path to the updated image
image_path = '/content/Dilip_Joshi.jpg'

# Function for face and emotion detection
def detect_faces_and_emotions(image_path):
    # Load the image
    image = cv2.imread(image_path)
    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Load pre-trained face detection model from OpenCV
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

    # Detect faces in the image
    faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

    print(f"Detected {len(faces)} face(s) in the image.")

    # Draw rectangles around detected faces
    for (x, y, w, h) in faces:
        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)

    # Display the image with detected faces
    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    plt.axis('off')
    plt.show()

    # Perform emotion analysis using DeepFace
    emotion_results = []
    for (x, y, w, h) in faces:
        # Crop the face region
        face_region = image[y:y + h, x:x + w]

        try:
            # Analyze emotions on the cropped face
            analysis = DeepFace.analyze(face_region, actions=['emotion'], enforce_detection=False)
            emotion = analysis['dominant_emotion']
            print(f"Emotion detected: {emotion}")
            emotion_results.append(emotion)
        except Exception as e:
            print(f"Error analyzing face: {e}")
            emotion_results.append(None)

    return emotion_results

# Main Execution
if __name__ == "__main__":
    # Detect faces and emotions
    emotions = detect_faces_and_emotions(image_path)

    # Print results
    print("Detected Emotions:", emotions)

# prompt: understand the emotion in above image needed doenload libraries

# Install necessary libraries if not already installed
!pip install opencv-python deepface matplotlib

# prompt: Give me emotion in image

import cv2
from deepface import DeepFace
import matplotlib.pyplot as plt

# Path to the updated image
image_path = '/content/Dilip_Joshi.jpg'

# Function for face and emotion detection
def detect_faces_and_emotions(image_path):
    # Load the image
    image = cv2.imread(image_path)
    if image is None:
        print(f"Error: Could not load image at {image_path}")
        return []

    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Load pre-trained face detection model from OpenCV
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

    # Detect faces in the image
    faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

    print(f"Detected {len(faces)} face(s) in the image.")

    # Draw rectangles around detected faces
    for (x, y, w, h) in faces:
        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)

    # Display the image with detected faces
    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    plt.axis('off')
    plt.show()

    # Perform emotion analysis using DeepFace
    emotion_results = []
    for (x, y, w, h) in faces:
        # Crop the face region
        face_region = image[y:y + h, x:x + w]

        try:
            # Analyze emotions on the cropped face
            analysis = DeepFace.analyze(face_region, actions=['emotion'], enforce_detection=False)
            emotion = analysis['dominant_emotion']
            print(f"Emotion detected: {emotion}")
            emotion_results.append(emotion)
        except Exception as e:
            print(f"Error analyzing face: {e}")
            emotion_results.append(None)

    return emotion_results

# Main Execution
if __name__ == "__main__":
    # Detect faces and emotions
    emotions = detect_faces_and_emotions(image_path)

    # Print results
    print("Detected Emotions:", emotions)